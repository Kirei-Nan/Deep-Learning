1. 右上角是人为决定的神经元的含义，DL中把每个神经元和features相连接让neural network自己决定每个神经元所代表的含义从而预测价格![image-20240117095701879](/Users/nanzhenghan/Library/Application Support/typora-user-images/image-20240117095701879.png)

2. 3 types of NN:

   ![image-20240117100441414](/Users/nanzhenghan/Library/Application Support/typora-user-images/image-20240117100441414.png)

3. 2 types of data: DL is now more good at unstructured data

   ![image-20240117101233893](/Users/nanzhenghan/Library/Application Support/typora-user-images/image-20240117101233893.png)

4. why is Deep learning taking off?

   ![image-20240117102831786](/Users/nanzhenghan/Library/Application Support/typora-user-images/image-20240117102831786.png)

   The effectiveness of a neural network's performance is influenced by two primary factors: 
   1. The neural network's scale.
   2. The volume of training data.

   In scenarios where training datasets are limited, the proficiency in feature engineering and the sophistication of algorithms become pivotal. Conversely, in instances with abundant data, the dimensions of the neural network play a more critical role in dictating performance.
   
   The recent surge in deep learning's prominence can be attributed to three key developments:
   1. Data Availability: The digital era has ushered in an era where society generates and accumulates vast quantities of data.
   2. Enhanced Computational Resources: Advancements in hardware, particularly GPUs, have significantly improved computational capabilities.
   3. Algorithmic Innovations: There has been a paradigm shift in algorithms, notably the transition from sigmoid to ReLU functions, which has markedly accelerated the efficiency of gradient descent processes.
   
   ![image-20240117103637188](/Users/nanzhenghan/Library/Application Support/typora-user-images/image-20240117103637188.png)
   
   because ReLU significantly changes the gradient